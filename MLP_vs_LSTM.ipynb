{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP vs LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAfIsnzF2ahSPdD5D43gab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakashradhakrish/NLP_comparison/blob/main/MLP_vs_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qODuUaulQOLK",
        "outputId": "280753ab-a556-44c3-f0fd-cbaba68964a4"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import time\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from bs4 import BeautifulSoup "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRZkTrE3QX4U",
        "outputId": "502ff5f4-0262-497d-e773-a229fcbea479"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFzPjBwiQX7V"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/LFD/IMDB_Dataset.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "1Laa7t-uQYBt",
        "outputId": "b8c21979-3ed3-4eb8-e0c2-a200ed04b910"
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "407ZWytlQYEm"
      },
      "source": [
        "corpus=[]\r\n",
        "ps = PorterStemmer()\r\n",
        "def clean_text_corpus(df):\r\n",
        "  for i in range(0,len(df)):\r\n",
        "    review = re.sub('[^a-zA-Z]', ' ', df['review'][i])\r\n",
        "    review = review.lower().split()\r\n",
        "    \r\n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\r\n",
        "    review = ' '.join(review)\r\n",
        "    corpus.append(review)\r\n",
        "  return corpus"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWaaxBviQYHd",
        "outputId": "c071a8c7-72c3-4a4a-f9bd-5ab8b5254116"
      },
      "source": [
        "st = time.time()\r\n",
        "cp_t = clean_text_corpus(df)\r\n",
        "print(\"- %s minutes - \" % round((time.time() - st)/60,2))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- 20.75 minutes - \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01DQZPASr2rz"
      },
      "source": [
        "with open('/content/drive/MyDrive/LFD/cp_t.txt', 'w') as f:\r\n",
        "    for item in cp_t:\r\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av8jghJURw3J"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "cv = CountVectorizer(max_features = 2500)\r\n",
        "X = cv.fit_transform(cp_t).toarray()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chwWG_4oRw6a"
      },
      "source": [
        "from sklearn import preprocessing\r\n",
        "le = preprocessing.LabelEncoder()\r\n",
        "y = le.fit_transform(df['sentiment'])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK-VrmsDRw9g"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "class trainData(Dataset):\r\n",
        "    \r\n",
        "    def __init__(self, X_data, y_data):\r\n",
        "        self.X_data = X_data\r\n",
        "        self.y_data = y_data\r\n",
        "        \r\n",
        "    def __getitem__(self, index):\r\n",
        "        return self.X_data[index], self.y_data[index]\r\n",
        "        \r\n",
        "    def __len__ (self):\r\n",
        "        return len(self.X_data)\r\n",
        "\r\n",
        "\r\n",
        "train_data = trainData(torch.FloatTensor(X), torch.FloatTensor(y))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl297oTcRxBI"
      },
      "source": [
        "batch_size = 16\r\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hGl07BBQYLV"
      },
      "source": [
        "class binaryClassification(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(binaryClassification, self).__init__()\r\n",
        "\r\n",
        "        self.layer_1 = nn.Linear(2500, 64) \r\n",
        "        self.layer_2 = nn.Linear(64, 64)\r\n",
        "        self.layer_out = nn.Linear(64, 1) \r\n",
        "        \r\n",
        "        self.relu = nn.ReLU()\r\n",
        "        self.dropout = nn.Dropout(p=0.1)\r\n",
        "        self.batchnorm1 = nn.BatchNorm1d(64)\r\n",
        "        self.batchnorm2 = nn.BatchNorm1d(64)\r\n",
        "        \r\n",
        "    def forward(self, inputs):\r\n",
        "        x = self.relu(self.layer_1(inputs))\r\n",
        "        x = self.batchnorm1(x)\r\n",
        "        x = self.relu(self.layer_2(x))\r\n",
        "        x = self.batchnorm2(x)\r\n",
        "        x = self.dropout(x)\r\n",
        "        x = self.layer_out(x)\r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7P-MyjuS6ey",
        "outputId": "cd3e2b9f-3591-4789-bf37-6a9875ad608c"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8hCua05S6h6",
        "outputId": "25b650f7-71e5-4526-e5de-f87bfac776d2"
      },
      "source": [
        "model = binaryClassification()\r\n",
        "model.to(device)\r\n",
        "print(model)\r\n",
        "\r\n",
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "binaryClassification(\n",
            "  (layer_1): Linear(in_features=2500, out_features=64, bias=True)\n",
            "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcZbr0i2S6k6"
      },
      "source": [
        "def binary_acc(y_pred, y_test):\r\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\r\n",
        "\r\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\r\n",
        "    acc = correct_results_sum/y_test.shape[0]\r\n",
        "    acc = torch.round(acc * 100)\r\n",
        "    \r\n",
        "    return acc"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMNxdfJoS6pd",
        "outputId": "c109d1a9-a2b7-424a-b835-aae65b6f0b2f"
      },
      "source": [
        "epoch = 50\r\n",
        "model.train()\r\n",
        "st = time.time()\r\n",
        "for e in range(1, epoch+1):\r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    for X_batch, y_batch in train_loader:\r\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        y_pred = model(X_batch)\r\n",
        "        \r\n",
        "        loss = criterion(y_pred, y_batch.unsqueeze(1))\r\n",
        "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc.item()\r\n",
        "        \r\n",
        "\r\n",
        "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\r\n",
        "\r\n",
        "print(\"- %s minutes - \" % round((time.time() - st)/60,2))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 001: | Loss: 0.36143 | Acc: 84.628\n",
            "Epoch 002: | Loss: 0.30595 | Acc: 87.492\n",
            "Epoch 003: | Loss: 0.27577 | Acc: 88.950\n",
            "Epoch 004: | Loss: 0.24775 | Acc: 90.321\n",
            "Epoch 005: | Loss: 0.21871 | Acc: 91.514\n",
            "Epoch 006: | Loss: 0.19481 | Acc: 92.868\n",
            "Epoch 007: | Loss: 0.18232 | Acc: 93.340\n",
            "Epoch 008: | Loss: 0.17241 | Acc: 93.584\n",
            "Epoch 009: | Loss: 0.15428 | Acc: 94.348\n",
            "Epoch 010: | Loss: 0.14179 | Acc: 95.003\n",
            "Epoch 011: | Loss: 0.13464 | Acc: 95.132\n",
            "Epoch 012: | Loss: 0.11835 | Acc: 95.961\n",
            "Epoch 013: | Loss: 0.12596 | Acc: 95.422\n",
            "Epoch 014: | Loss: 0.11667 | Acc: 95.876\n",
            "Epoch 015: | Loss: 0.11154 | Acc: 96.060\n",
            "Epoch 016: | Loss: 0.11002 | Acc: 96.138\n",
            "Epoch 017: | Loss: 0.10259 | Acc: 96.356\n",
            "Epoch 018: | Loss: 0.10883 | Acc: 96.264\n",
            "Epoch 019: | Loss: 0.09264 | Acc: 96.804\n",
            "Epoch 020: | Loss: 0.08960 | Acc: 96.886\n",
            "Epoch 021: | Loss: 0.08296 | Acc: 97.135\n",
            "Epoch 022: | Loss: 0.08521 | Acc: 97.102\n",
            "Epoch 023: | Loss: 0.08682 | Acc: 96.987\n",
            "Epoch 024: | Loss: 0.08634 | Acc: 97.095\n",
            "Epoch 025: | Loss: 0.08071 | Acc: 97.186\n",
            "Epoch 026: | Loss: 0.07502 | Acc: 97.491\n",
            "Epoch 027: | Loss: 0.07542 | Acc: 97.485\n",
            "Epoch 028: | Loss: 0.07367 | Acc: 97.542\n",
            "Epoch 029: | Loss: 0.06866 | Acc: 97.750\n",
            "Epoch 030: | Loss: 0.06627 | Acc: 97.871\n",
            "Epoch 031: | Loss: 0.06748 | Acc: 97.734\n",
            "Epoch 032: | Loss: 0.06544 | Acc: 97.847\n",
            "Epoch 033: | Loss: 0.06790 | Acc: 97.786\n",
            "Epoch 034: | Loss: 0.06294 | Acc: 97.928\n",
            "Epoch 035: | Loss: 0.06381 | Acc: 97.893\n",
            "Epoch 036: | Loss: 0.05755 | Acc: 98.194\n",
            "Epoch 037: | Loss: 0.05441 | Acc: 98.210\n",
            "Epoch 038: | Loss: 0.05524 | Acc: 98.265\n",
            "Epoch 039: | Loss: 0.05499 | Acc: 98.182\n",
            "Epoch 040: | Loss: 0.06017 | Acc: 98.061\n",
            "Epoch 041: | Loss: 0.05721 | Acc: 98.153\n",
            "Epoch 042: | Loss: 0.06001 | Acc: 98.126\n",
            "Epoch 043: | Loss: 0.05873 | Acc: 98.089\n",
            "Epoch 044: | Loss: 0.05314 | Acc: 98.383\n",
            "Epoch 045: | Loss: 0.05520 | Acc: 98.264\n",
            "Epoch 046: | Loss: 0.05629 | Acc: 98.264\n",
            "Epoch 047: | Loss: 0.05944 | Acc: 98.131\n",
            "Epoch 048: | Loss: 0.05294 | Acc: 98.383\n",
            "Epoch 049: | Loss: 0.05637 | Acc: 98.238\n",
            "Epoch 050: | Loss: 0.05471 | Acc: 98.331\n",
            "- 8.14 minutes - \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2RTrwg3TRpD"
      },
      "source": [
        "import os\r\n",
        "torch.save(model.state_dict(), os.path.join(\"/content/drive/MyDrive/LFD/\",\"trained_model_18_12_2020.pth\"))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfQi6afqo-m3"
      },
      "source": [
        "test_data = ['movie is good']\r\n",
        "test_data = pd.DataFrame(test_data,columns=['review'])\r\n",
        "no_of_rows=len(test_data)\r\n",
        "cp_test = clean_text_corpus(test_data)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Uy-7lcTRwF"
      },
      "source": [
        "test_X = cv.fit_transform(cp_test).toarray()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZJFTV9qQ0a"
      },
      "source": [
        "tp = torch.Tensor(test_X[-1])\r\n",
        "tp = tp.reshape(1,len(tp))"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RDYr7zITRzv"
      },
      "source": [
        "model.eval()\r\n",
        "test_y = model(tp.to(device))"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PXuf2_nS6tF",
        "outputId": "51299983-e322-4e68-8ceb-d08d6ca4784d"
      },
      "source": [
        "test_y"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.7805]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSyCa1fVtVsm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}